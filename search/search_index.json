{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Course description NGS technologies allow researchers to sequence genomes and transcriptomes of almost any organism within a few days. However, the assembly and annotation is still very challenging and requires a deep understanding of assembly algorithms and sequencing technologies. Learning outcomes Empower the students to independently de novo assemble genomes and transcriptomes 2nd and 3rd generation sequencing. Students (i) learn the theory of algorithmic assembly principles, (ii) apply it to data sets of both model & non-model organisms, (iii) assess the quality along the complete process from data generation to the genome/transcriptome assembly itself, (iv) annotate the genome by mapping the transcriptome assembly data to genome assembly data. Datasets The datasets used in this course originate from: Jiao WB, Schneeberger K. Chromosome-level assemblies of multiple Arabidopsis genomes reveal hotspots of rearrangements with altered evolutionary dynamics. Nature Communications. 2020;11:1\u201310. Available from: http://dx.doi.org/10.1038/s41467-020-14779-y Teachers Assembly part R\u00e9my Bruggmann Heidi Tschanz-Lischer David M.F. Francisco Geert van Geest Annotation part Christian Parisod Manuel Poretti","title":"Home"},{"location":"#course-description","text":"NGS technologies allow researchers to sequence genomes and transcriptomes of almost any organism within a few days. However, the assembly and annotation is still very challenging and requires a deep understanding of assembly algorithms and sequencing technologies.","title":"Course description"},{"location":"#learning-outcomes","text":"Empower the students to independently de novo assemble genomes and transcriptomes 2nd and 3rd generation sequencing. Students (i) learn the theory of algorithmic assembly principles, (ii) apply it to data sets of both model & non-model organisms, (iii) assess the quality along the complete process from data generation to the genome/transcriptome assembly itself, (iv) annotate the genome by mapping the transcriptome assembly data to genome assembly data.","title":"Learning outcomes"},{"location":"#datasets","text":"The datasets used in this course originate from: Jiao WB, Schneeberger K. Chromosome-level assemblies of multiple Arabidopsis genomes reveal hotspots of rearrangements with altered evolutionary dynamics. Nature Communications. 2020;11:1\u201310. Available from: http://dx.doi.org/10.1038/s41467-020-14779-y","title":"Datasets"},{"location":"#teachers","text":"","title":"Teachers"},{"location":"#assembly-part","text":"R\u00e9my Bruggmann Heidi Tschanz-Lischer David M.F. Francisco Geert van Geest","title":"Assembly part"},{"location":"#annotation-part","text":"Christian Parisod Manuel Poretti","title":"Annotation part"},{"location":"course_schedule/","text":"Week 1 block start end subject block 1 9:15 AM 10:45 AM Lecture 1: introduction to genome assembly 10:45 AM 11:00 AM break block 2 11:00 AM 12:30 PM Exercises: access reads and perform basic QC 12:30 PM 1:30 PM break block 3 1:30 PM 3:00 PM Lecture 2: generating sequencing reads 3:00 PM 3:30 PM break block 4 4:00 PM 5:00 PM Exercises: kmer analysis Week 2 block start end subject block 1 9:15 AM 10:45 AM Lecture 3: Assembly theory + assembly software 10:45 AM 11:00 AM break 11:00 AM 11:30 PM Demo: Nanopore sequencing block 2 11:30 AM 12:30 PM Exercises: perform your own assembly 12:30 PM 1:30 PM break block 3 1:30 PM 2:00 PM Lecture 4: Transcriptome assembly 1:30 PM 3:00 PM Exercises: perform your own assembly 3:00 PM 3:30 PM break block 4 3:30 PM 5:00 PM Exercises: perform your own assembly Week 3 block start end subject block 1 9:15 AM 10:45 AM Lecture 5: Assembly evaluation 10:45 AM 11:00 AM break block 2 11:00 AM 12:30 PM Exercises: assembly evaluation 12:30 PM 1:30 PM break block 3 1:30 PM 3:00 PM Prepare Presentation 3:00 PM 3:30 PM break block 4 3:30 PM 5:00 PM Prepare Presentation Week 4 block start end subject block 1 9:15 AM 9:45 AM Lecture 6: comparing genomes block 2.1 9:45 AM 10:45 AM Exercises: comparing genomes 10:45 AM 11:00 AM break block 2.2 11:00 AM 12:30 PM Exercises: comparing genomes (continue) 12:30 PM 1:30 PM break block 3 1:30 PM 3:00 PM Presentations 3:00 PM 3:30 PM break block 4 3:30 PM 5:00 PM Presentations","title":"Course schedule"},{"location":"course_schedule/#week-1","text":"block start end subject block 1 9:15 AM 10:45 AM Lecture 1: introduction to genome assembly 10:45 AM 11:00 AM break block 2 11:00 AM 12:30 PM Exercises: access reads and perform basic QC 12:30 PM 1:30 PM break block 3 1:30 PM 3:00 PM Lecture 2: generating sequencing reads 3:00 PM 3:30 PM break block 4 4:00 PM 5:00 PM Exercises: kmer analysis","title":"Week 1"},{"location":"course_schedule/#week-2","text":"block start end subject block 1 9:15 AM 10:45 AM Lecture 3: Assembly theory + assembly software 10:45 AM 11:00 AM break 11:00 AM 11:30 PM Demo: Nanopore sequencing block 2 11:30 AM 12:30 PM Exercises: perform your own assembly 12:30 PM 1:30 PM break block 3 1:30 PM 2:00 PM Lecture 4: Transcriptome assembly 1:30 PM 3:00 PM Exercises: perform your own assembly 3:00 PM 3:30 PM break block 4 3:30 PM 5:00 PM Exercises: perform your own assembly","title":"Week 2"},{"location":"course_schedule/#week-3","text":"block start end subject block 1 9:15 AM 10:45 AM Lecture 5: Assembly evaluation 10:45 AM 11:00 AM break block 2 11:00 AM 12:30 PM Exercises: assembly evaluation 12:30 PM 1:30 PM break block 3 1:30 PM 3:00 PM Prepare Presentation 3:00 PM 3:30 PM break block 4 3:30 PM 5:00 PM Prepare Presentation","title":"Week 3"},{"location":"course_schedule/#week-4","text":"block start end subject block 1 9:15 AM 9:45 AM Lecture 6: comparing genomes block 2.1 9:45 AM 10:45 AM Exercises: comparing genomes 10:45 AM 11:00 AM break block 2.2 11:00 AM 12:30 PM Exercises: comparing genomes (continue) 12:30 PM 1:30 PM break block 3 1:30 PM 3:00 PM Presentations 3:00 PM 3:30 PM break block 4 3:30 PM 5:00 PM Presentations","title":"Week 4"},{"location":"Annotation/week5/","text":"","title":"Week 5"},{"location":"Assembly/week1/","text":"Material Lecture 1: introduction to genome assembly Download the presentation Lecture 2: generating sequencing reads Download the presentation Raw input reads During this course we will work with raw data from: Jiao WB, Schneeberger K. Chromosome-level assemblies of multiple Arabidopsis genomes reveal hotspots of rearrangements with altered evolutionary dynamics. Nature Communications. 2020;11:1\u201310. Available from: http://dx.doi.org/10.1038/s41467-020-14779-y You can find the input reads at /data/courses/assembly-annotation-course . Each group gets appointed a separate accession (i.e. genotype) and each person gets assigned a separate dataset within an accession. Find the directory with your dataset like this: /data/courses/assembly-annotation-course/[ACCESSION]/[DATASET] The directory contains the following subdirectories + files (this is an example for An-1): . \u251c\u2500\u2500 Illumina \u2502 \u251c\u2500\u2500 ERR3624579_1.fastq.gz \u2502 \u2514\u2500\u2500 ERR3624579_2.fastq.gz \u251c\u2500\u2500 pacbio \u2502 \u251c\u2500\u2500 ERR3415817.fastq.gz \u2502 \u2514\u2500\u2500 ERR3415818.fastq.gz \u2514\u2500\u2500 RNAseq \u251c\u2500\u2500 ERR754061_1.fastq.gz \u2514\u2500\u2500 ERR754061_2.fastq.gz Containing three sequencing datasets: Whole genome Illumina ( Illumina ) Whole genome PacBio ( pacbio ) Whole transcriptome Illumina RNA-seq ( RNAseq ) Generate a working directory for this course in your data directory at /data/users/[USERNAME]/assembly_annotation_course . After that, generate a soft link to the directory with reads to get easy access: cd /data/users/ [ USERNAME ] /assembly_annotation_course ln -s /data/courses/assembly-annotation-course/ [ ACCESSION ] / [ DATASET ] / ./ Basic read statistics In this first exercise you will get acquainted with the different datasets and run some basic QC on them. Exercise: Run fastqc on each of the fastq files. To do this, first look up the required module at https://www.vital-it.ch/services , and create a script to run fastqc using SLURM\u2019s sbatch . using SLURM A tutorial about job submission using SLURM on the IBU cluster you can find here . Work structured! You will use the same dataset throughout this course. Since your building further on your results it is important to keep track of the commands you have run. Therefore, it makes sense to have a directory scripts in your working directory (i.e. /data/users/[USERNAME]/assembly_annotation_course ). In addition, it also helps to keep files related to the same step in the process in the same directory. A directory structure of your working directory could therefore look like this: . \u251c\u2500\u2500 assemblies \u2502 \u251c\u2500\u2500 canu \u2502 \u251c\u2500\u2500 flye \u2502 \u2514\u2500\u2500 Trinity \u251c\u2500\u2500 read_QC \u2502 \u251c\u2500\u2500 fastqc \u2502 \u2514\u2500\u2500 kmer_counting \u2514\u2500\u2500 scripts \u251c\u2500\u2500 01_read_statistics.sh \u2514\u2500\u2500 02_kmer_counting.sh Questions: What are the read lengths of the different datasets? What kind of coverage do you expect from the Pacbio and the Illumina WGS reads? ( hint : lookup the expected genome size of Arabidopsis thaliana ) Do all datasets have information on base quality? Perform k-mer counting Exercise: Go to http://qb.cshl.edu/genomescope/ , and follow their suggestions on counting k-mers ( jellyfish count ) and creating a histogram ( jellyfish histo ). Other than what is suggested on the genomescope website, you can use the options -s 5G (hash of 5Gb) and -t 4 (4 threads). The other options you can keep the same as suggested on the website. Again, submit the commands from within a script using sbatch . jellyfish count only accepts uncompressed input Your fastq files are compressed (i.e. ending with fastq.gz ). jellyfish can not read those directly, but you can provide the files with process substitution of zcat , i.e.: jellyfish count \\ [ OPTIONS ] \\ < ( zcat myreads.fastq.gz ) \\ < ( zcat myotherreads.fastq.gz ) Questions: Upload your histo file to the website, checkout the plots and answer the following questions: Why are we using canonical k-mers? Is the estimated genome size expected? Is the percentage of heterozygousity expected?","title":"Week 1 - reads & QC"},{"location":"Assembly/week1/#material","text":"Lecture 1: introduction to genome assembly Download the presentation Lecture 2: generating sequencing reads Download the presentation","title":"Material"},{"location":"Assembly/week1/#raw-input-reads","text":"During this course we will work with raw data from: Jiao WB, Schneeberger K. Chromosome-level assemblies of multiple Arabidopsis genomes reveal hotspots of rearrangements with altered evolutionary dynamics. Nature Communications. 2020;11:1\u201310. Available from: http://dx.doi.org/10.1038/s41467-020-14779-y You can find the input reads at /data/courses/assembly-annotation-course . Each group gets appointed a separate accession (i.e. genotype) and each person gets assigned a separate dataset within an accession. Find the directory with your dataset like this: /data/courses/assembly-annotation-course/[ACCESSION]/[DATASET] The directory contains the following subdirectories + files (this is an example for An-1): . \u251c\u2500\u2500 Illumina \u2502 \u251c\u2500\u2500 ERR3624579_1.fastq.gz \u2502 \u2514\u2500\u2500 ERR3624579_2.fastq.gz \u251c\u2500\u2500 pacbio \u2502 \u251c\u2500\u2500 ERR3415817.fastq.gz \u2502 \u2514\u2500\u2500 ERR3415818.fastq.gz \u2514\u2500\u2500 RNAseq \u251c\u2500\u2500 ERR754061_1.fastq.gz \u2514\u2500\u2500 ERR754061_2.fastq.gz Containing three sequencing datasets: Whole genome Illumina ( Illumina ) Whole genome PacBio ( pacbio ) Whole transcriptome Illumina RNA-seq ( RNAseq ) Generate a working directory for this course in your data directory at /data/users/[USERNAME]/assembly_annotation_course . After that, generate a soft link to the directory with reads to get easy access: cd /data/users/ [ USERNAME ] /assembly_annotation_course ln -s /data/courses/assembly-annotation-course/ [ ACCESSION ] / [ DATASET ] / ./","title":"Raw input reads"},{"location":"Assembly/week1/#basic-read-statistics","text":"In this first exercise you will get acquainted with the different datasets and run some basic QC on them. Exercise: Run fastqc on each of the fastq files. To do this, first look up the required module at https://www.vital-it.ch/services , and create a script to run fastqc using SLURM\u2019s sbatch . using SLURM A tutorial about job submission using SLURM on the IBU cluster you can find here . Work structured! You will use the same dataset throughout this course. Since your building further on your results it is important to keep track of the commands you have run. Therefore, it makes sense to have a directory scripts in your working directory (i.e. /data/users/[USERNAME]/assembly_annotation_course ). In addition, it also helps to keep files related to the same step in the process in the same directory. A directory structure of your working directory could therefore look like this: . \u251c\u2500\u2500 assemblies \u2502 \u251c\u2500\u2500 canu \u2502 \u251c\u2500\u2500 flye \u2502 \u2514\u2500\u2500 Trinity \u251c\u2500\u2500 read_QC \u2502 \u251c\u2500\u2500 fastqc \u2502 \u2514\u2500\u2500 kmer_counting \u2514\u2500\u2500 scripts \u251c\u2500\u2500 01_read_statistics.sh \u2514\u2500\u2500 02_kmer_counting.sh Questions: What are the read lengths of the different datasets? What kind of coverage do you expect from the Pacbio and the Illumina WGS reads? ( hint : lookup the expected genome size of Arabidopsis thaliana ) Do all datasets have information on base quality?","title":"Basic read statistics"},{"location":"Assembly/week1/#perform-k-mer-counting","text":"Exercise: Go to http://qb.cshl.edu/genomescope/ , and follow their suggestions on counting k-mers ( jellyfish count ) and creating a histogram ( jellyfish histo ). Other than what is suggested on the genomescope website, you can use the options -s 5G (hash of 5Gb) and -t 4 (4 threads). The other options you can keep the same as suggested on the website. Again, submit the commands from within a script using sbatch . jellyfish count only accepts uncompressed input Your fastq files are compressed (i.e. ending with fastq.gz ). jellyfish can not read those directly, but you can provide the files with process substitution of zcat , i.e.: jellyfish count \\ [ OPTIONS ] \\ < ( zcat myreads.fastq.gz ) \\ < ( zcat myotherreads.fastq.gz ) Questions: Upload your histo file to the website, checkout the plots and answer the following questions: Why are we using canonical k-mers? Is the estimated genome size expected? Is the percentage of heterozygousity expected?","title":"Perform k-mer counting"},{"location":"Assembly/week2/","text":"Introduction Today we will start with generating three assemblies: Whole genome assembly using flye Whole genome assembly using canu Whole transcriptome assembly using Trinity Note that assemblies are generally compute intense, particularly in terms of memory. So, your jobs will take at least a few hours to complete and require quite some memory. While flye and Trinity run within a single job, canu creates different job steps for you. This means that for flye and Trinity you will need to reserve the appropriate CPU and memory by using the sbatch options. The canu command itself runs very quickly, and it submits different jobs automatically that are needed to complete the canu assembly. flye assembly Generate and run a script for performing the flye assembly from the pacbio reads that you can submit using sbatch . Use (amongst others) the following sbatch options: #SBATCH --time=06:00:00 #SBATCH --mem-per-cpu=4G #SBATCH --cpus-per-task=16 Hint Find the usage of flye here canu assembly Generate and run a script for performing the canu assembly from the pacbio reads. Have a look here to get started. In addition, you will need some specific options to tell canu how to submit to the cluster, these are: gridEngineResourceOption : the options how canu can specify resources within a job. For SLURM this is: gridEngineResourceOption=\"--cpus-per-task=THREADS --mem-per-cpu=MEMORY\" gridOptions : options you would otherwise add to the sbatch options, e.g.: gridOptions=\"--partion=pall --mail-user=mymail@students.unibe.ch\" More information on grid configuration here As canu creates the jobs for you, you can submit the canu command itself with limited resources, e.g.: #SBATCH --time=01:00:00 #SBATCH --mem-per-cpu=4G #SBATCH --cpus-per-task=1 Trinity assembly Find information on how to run Trinity here . You can provide multiple fastq files if they are separated by a comma. You can use (amongst others) the following sbatch options: #SBATCH --time=1-00:00:00 #SBATCH --mem-per-cpu=4G #SBATCH --cpus-per-task=12","title":"Week 2 - assembly"},{"location":"Assembly/week2/#introduction","text":"Today we will start with generating three assemblies: Whole genome assembly using flye Whole genome assembly using canu Whole transcriptome assembly using Trinity Note that assemblies are generally compute intense, particularly in terms of memory. So, your jobs will take at least a few hours to complete and require quite some memory. While flye and Trinity run within a single job, canu creates different job steps for you. This means that for flye and Trinity you will need to reserve the appropriate CPU and memory by using the sbatch options. The canu command itself runs very quickly, and it submits different jobs automatically that are needed to complete the canu assembly.","title":"Introduction"},{"location":"Assembly/week2/#flye-assembly","text":"Generate and run a script for performing the flye assembly from the pacbio reads that you can submit using sbatch . Use (amongst others) the following sbatch options: #SBATCH --time=06:00:00 #SBATCH --mem-per-cpu=4G #SBATCH --cpus-per-task=16 Hint Find the usage of flye here","title":"flye assembly"},{"location":"Assembly/week2/#canu-assembly","text":"Generate and run a script for performing the canu assembly from the pacbio reads. Have a look here to get started. In addition, you will need some specific options to tell canu how to submit to the cluster, these are: gridEngineResourceOption : the options how canu can specify resources within a job. For SLURM this is: gridEngineResourceOption=\"--cpus-per-task=THREADS --mem-per-cpu=MEMORY\" gridOptions : options you would otherwise add to the sbatch options, e.g.: gridOptions=\"--partion=pall --mail-user=mymail@students.unibe.ch\" More information on grid configuration here As canu creates the jobs for you, you can submit the canu command itself with limited resources, e.g.: #SBATCH --time=01:00:00 #SBATCH --mem-per-cpu=4G #SBATCH --cpus-per-task=1","title":"canu assembly"},{"location":"Assembly/week2/#trinity-assembly","text":"Find information on how to run Trinity here . You can provide multiple fastq files if they are separated by a comma. You can use (amongst others) the following sbatch options: #SBATCH --time=1-00:00:00 #SBATCH --mem-per-cpu=4G #SBATCH --cpus-per-task=12","title":"Trinity assembly"},{"location":"Assembly/week3/","text":"Run containers Some software requires very specific dependencies and can not be installed as a module. These kind of software are available in containers. You can find them (like the modules) through the vital-it website . You can run the containers with singularity . The syntax is like this: singularity exec --bind [path to working directory] [path to container] [command] . You can find more information on the container of interest like this: # example for Merqury: singularity run-help /software/singularity/containers/Merqury-1.3-1.ubuntu20.sif Running the program merqury.sh inside this container would look like: WORKDIR = /path/to/work/directory singularity exec \\ --bind $WORKDIR \\ /software/singularity/containers/Merqury-1.3-1.ubuntu20.sif \\ merqury.sh \\ --help Note that singularity is not available on the head node (binfservms01). Therefore you can run singularity only within a job on any other node on the cluster. To quickly check the helper you can use: srun singularity run-help /software/singularity/containers/Merqury-1.3-1.ubuntu20.sif To run the container (or any larger process) it\u2019s best to submit it as a job with sbatch . For this create a script (e.g. merqury.sh ): #!/usr/bin/env bash #SBATCH --time=1-00:00:00 #SBATCH --mem-per-cpu=4G #SBATCH --cpus-per-task=4 #SBATCH --job-name=merqury PROJDIR = /path/to/project/dir singularity exec \\ --bind $PROJDIR \\ /software/singularity/containers/Merqury-1.3-1.ubuntu20.sif \\ merqury.sh \\ $PROJDIR /quality_control/meryl/Ler.meryl \\ $PROJDIR /assemblies/flye.fasta \\ flye_test And submit it with: sbatch merqury.sh Assessing quality with BUSCO BUSCO uses gene sets that are expected to be \u2018universal\u2019 and single-copy among groups of organisms. This means that from such a gene set, you should be able to find most of them only once in your assembly. If you only find a few, it probably means your assembly does not represent the complete genome/transcriptome, if you find many in multiple times, your assembly probably contains a lot of sequences that should be merged. Exercise: Run BUSCO on each of your assemblies (i.e. whole genome with flye and canu , and transcriptome generated with Trinity ). As the lineage you can use brassicales_odb10 . You can use the following container: /data/courses/assembly-annotation-course/containers/busco_5.1.3--pyhdfd78af_0.sif Options to use Before you start running the program, check out the helper ( busco --help ) and have a look in particular at the following options: --mode --lineage --cpu Questions: How do your genome assemblies look according to your BUSCO results? Is one genome assembly better than the other? How does your transcriptome assembly look? Are there many duplicated genes? Can you explain the differences with the whole genome assemblies? Assessing quality of quast #!/usr/bin/env bash #SBATCH --mail-user=geert.vangeest@bioinformatics.unibe.ch #SBATCH --mail-type=end,fail #SBATCH --time=00:05:00 #SBATCH --mem-per-cpu=4G #SBATCH --cpus-per-task=4 #SBATCH --output=/data/projects/p651_Assembly_and_annotation_course_2021/assembly_Ler/log/quast_output_%j.txt #SBATCH --error=/data/projects/p651_Assembly_and_annotation_course_2021/assembly_Ler/log/quast_error_%j.txt #SBATCH --job-name=p651_quast #SBATCH --partition=pall PROJDIR = /data/projects/p651_Assembly_and_annotation_course_2021/assembly_Ler mkdir -p $PROJDIR /quality_control/quast cd $PROJDIR /quality_control/quast singularity exec \\ --bind $PROJDIR \\ $PROJDIR /../containers/quast_5.1.0rc1.sif \\ quast.py \\ --output-dir $PROJDIR /quality_control/quast \\ --min-contig 100 \\ --threads ${ SLURM_CPUS_PER_TASK } \\ --eukaryote \\ --est-ref-size 135000000 \\ --labels flye,canu \\ $PROJDIR /assemblies/flye.fasta \\ $PROJDIR /assemblies/canu.fasta merqury Look at: https://kat.readthedocs.io/en/latest/walkthrough.html#genome-assembly-analysis-using-k-mer-spectra #!/usr/bin/env bash #SBATCH --mail-user=geert.vangeest@bioinformatics.unibe.ch #SBATCH --mail-type=end,fail #SBATCH --time=1-00:00:00 #SBATCH --mem-per-cpu=4G #SBATCH --cpus-per-task=4 #SBATCH --output=/data/projects/p651_Assembly_and_annotation_course_2021/assembly_Ler/log/merqury_output_%j.txt #SBATCH --error=/data/projects/p651_Assembly_and_annotation_course_2021/assembly_Ler/log/merqury_error_%j.txt #SBATCH --job-name=p651_merqury #SBATCH --partition=pall PROJDIR = /data/projects/p651_Assembly_and_annotation_course_2021/assembly_Ler mkdir -p $PROJDIR /quality_control/meryl mkdir -p $PROJDIR /quality_control/merqury mkdir -p $PROJDIR /assemblies ln -s $PROJDIR /Ler-deNovoAssembly_flye/assembly.fasta $PROJDIR /assemblies/flye.fasta ln -s $PROJDIR /Ler-deNovoAssembly_canu/Ler.contigs.fasta $PROJDIR /assemblies/canu.fasta # singularity exec \\ # --bind $PROJDIR \\ # /software/singularity/containers/Merqury-1.3-1.ubuntu20.sif \\ # best_k.sh 135000000 singularity exec \\ --bind $PROJDIR \\ /software/singularity/containers/Merqury-1.3-1.ubuntu20.sif \\ meryl \\ k = 18 \\ count output \\ $PROJDIR /quality_control/meryl/Ler.meryl \\ $PROJDIR /reads/ERR3624574_1.fastq.gz $PROJDIR /reads/ERR3624574_2.fastq.gz cd $PROJDIR /quality_control/merqury/ singularity exec \\ --bind $PROJDIR \\ /software/singularity/containers/Merqury-1.3-1.ubuntu20.sif \\ merqury.sh \\ $PROJDIR /quality_control/meryl/Ler.meryl \\ $PROJDIR /assemblies/flye.fasta \\ flye_test","title":"Week 3 - assembly evaluation"},{"location":"Assembly/week3/#run-containers","text":"Some software requires very specific dependencies and can not be installed as a module. These kind of software are available in containers. You can find them (like the modules) through the vital-it website . You can run the containers with singularity . The syntax is like this: singularity exec --bind [path to working directory] [path to container] [command] . You can find more information on the container of interest like this: # example for Merqury: singularity run-help /software/singularity/containers/Merqury-1.3-1.ubuntu20.sif Running the program merqury.sh inside this container would look like: WORKDIR = /path/to/work/directory singularity exec \\ --bind $WORKDIR \\ /software/singularity/containers/Merqury-1.3-1.ubuntu20.sif \\ merqury.sh \\ --help Note that singularity is not available on the head node (binfservms01). Therefore you can run singularity only within a job on any other node on the cluster. To quickly check the helper you can use: srun singularity run-help /software/singularity/containers/Merqury-1.3-1.ubuntu20.sif To run the container (or any larger process) it\u2019s best to submit it as a job with sbatch . For this create a script (e.g. merqury.sh ): #!/usr/bin/env bash #SBATCH --time=1-00:00:00 #SBATCH --mem-per-cpu=4G #SBATCH --cpus-per-task=4 #SBATCH --job-name=merqury PROJDIR = /path/to/project/dir singularity exec \\ --bind $PROJDIR \\ /software/singularity/containers/Merqury-1.3-1.ubuntu20.sif \\ merqury.sh \\ $PROJDIR /quality_control/meryl/Ler.meryl \\ $PROJDIR /assemblies/flye.fasta \\ flye_test And submit it with: sbatch merqury.sh","title":"Run containers"},{"location":"Assembly/week3/#assessing-quality-with-busco","text":"BUSCO uses gene sets that are expected to be \u2018universal\u2019 and single-copy among groups of organisms. This means that from such a gene set, you should be able to find most of them only once in your assembly. If you only find a few, it probably means your assembly does not represent the complete genome/transcriptome, if you find many in multiple times, your assembly probably contains a lot of sequences that should be merged. Exercise: Run BUSCO on each of your assemblies (i.e. whole genome with flye and canu , and transcriptome generated with Trinity ). As the lineage you can use brassicales_odb10 . You can use the following container: /data/courses/assembly-annotation-course/containers/busco_5.1.3--pyhdfd78af_0.sif Options to use Before you start running the program, check out the helper ( busco --help ) and have a look in particular at the following options: --mode --lineage --cpu Questions: How do your genome assemblies look according to your BUSCO results? Is one genome assembly better than the other? How does your transcriptome assembly look? Are there many duplicated genes? Can you explain the differences with the whole genome assemblies?","title":"Assessing quality with BUSCO"},{"location":"Assembly/week3/#assessing-quality-of-quast","text":"#!/usr/bin/env bash #SBATCH --mail-user=geert.vangeest@bioinformatics.unibe.ch #SBATCH --mail-type=end,fail #SBATCH --time=00:05:00 #SBATCH --mem-per-cpu=4G #SBATCH --cpus-per-task=4 #SBATCH --output=/data/projects/p651_Assembly_and_annotation_course_2021/assembly_Ler/log/quast_output_%j.txt #SBATCH --error=/data/projects/p651_Assembly_and_annotation_course_2021/assembly_Ler/log/quast_error_%j.txt #SBATCH --job-name=p651_quast #SBATCH --partition=pall PROJDIR = /data/projects/p651_Assembly_and_annotation_course_2021/assembly_Ler mkdir -p $PROJDIR /quality_control/quast cd $PROJDIR /quality_control/quast singularity exec \\ --bind $PROJDIR \\ $PROJDIR /../containers/quast_5.1.0rc1.sif \\ quast.py \\ --output-dir $PROJDIR /quality_control/quast \\ --min-contig 100 \\ --threads ${ SLURM_CPUS_PER_TASK } \\ --eukaryote \\ --est-ref-size 135000000 \\ --labels flye,canu \\ $PROJDIR /assemblies/flye.fasta \\ $PROJDIR /assemblies/canu.fasta","title":"Assessing quality of quast"},{"location":"Assembly/week3/#merqury","text":"Look at: https://kat.readthedocs.io/en/latest/walkthrough.html#genome-assembly-analysis-using-k-mer-spectra #!/usr/bin/env bash #SBATCH --mail-user=geert.vangeest@bioinformatics.unibe.ch #SBATCH --mail-type=end,fail #SBATCH --time=1-00:00:00 #SBATCH --mem-per-cpu=4G #SBATCH --cpus-per-task=4 #SBATCH --output=/data/projects/p651_Assembly_and_annotation_course_2021/assembly_Ler/log/merqury_output_%j.txt #SBATCH --error=/data/projects/p651_Assembly_and_annotation_course_2021/assembly_Ler/log/merqury_error_%j.txt #SBATCH --job-name=p651_merqury #SBATCH --partition=pall PROJDIR = /data/projects/p651_Assembly_and_annotation_course_2021/assembly_Ler mkdir -p $PROJDIR /quality_control/meryl mkdir -p $PROJDIR /quality_control/merqury mkdir -p $PROJDIR /assemblies ln -s $PROJDIR /Ler-deNovoAssembly_flye/assembly.fasta $PROJDIR /assemblies/flye.fasta ln -s $PROJDIR /Ler-deNovoAssembly_canu/Ler.contigs.fasta $PROJDIR /assemblies/canu.fasta # singularity exec \\ # --bind $PROJDIR \\ # /software/singularity/containers/Merqury-1.3-1.ubuntu20.sif \\ # best_k.sh 135000000 singularity exec \\ --bind $PROJDIR \\ /software/singularity/containers/Merqury-1.3-1.ubuntu20.sif \\ meryl \\ k = 18 \\ count output \\ $PROJDIR /quality_control/meryl/Ler.meryl \\ $PROJDIR /reads/ERR3624574_1.fastq.gz $PROJDIR /reads/ERR3624574_2.fastq.gz cd $PROJDIR /quality_control/merqury/ singularity exec \\ --bind $PROJDIR \\ /software/singularity/containers/Merqury-1.3-1.ubuntu20.sif \\ merqury.sh \\ $PROJDIR /quality_control/meryl/Ler.meryl \\ $PROJDIR /assemblies/flye.fasta \\ flye_test","title":"merqury"},{"location":"Assembly/week4/","text":"Run nucmer and mummer #!/usr/bin/env bash module add UHTS/Analysis/mummer/4.0.0beta1 PROJDIR = /data/projects/p651_Assembly_and_annotation_course_2021/assembly_Ler REFERENCE = $PROJDIR /assemblies/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa FLYE = $PROJDIR /assemblies/flye.fasta CANU = $PROJDIR /assemblies/canu.fasta mkdir -p $PROJDIR /quality_control/mummer/ ## gnu plot installed with conda ## conda install -c conda-forge gnuplot for GENOME in $FLYE $CANU do BASE = ` basename $GENOME | cut -f 1 -d '.' ` nucmer \\ --prefix = $PROJDIR /quality_control/mummer/Ler_ ${ BASE } \\ --breaklen 1000 \\ --mincluster 1000 \\ $REFERENCE \\ $GENOME mummerplot \\ $PROJDIR /quality_control/mummer/Ler_ ${ BASE } .delta \\ -R $REFERENCE \\ -Q $GENOME \\ --filter \\ -p $PROJDIR /quality_control/mummer/Ler_ ${ BASE } _plot \\ -t png \\ --fat \\ --large \\ --layout done","title":"Week 4 - comparing genomes"},{"location":"Assembly/week4/#run-nucmer-and-mummer","text":"#!/usr/bin/env bash module add UHTS/Analysis/mummer/4.0.0beta1 PROJDIR = /data/projects/p651_Assembly_and_annotation_course_2021/assembly_Ler REFERENCE = $PROJDIR /assemblies/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa FLYE = $PROJDIR /assemblies/flye.fasta CANU = $PROJDIR /assemblies/canu.fasta mkdir -p $PROJDIR /quality_control/mummer/ ## gnu plot installed with conda ## conda install -c conda-forge gnuplot for GENOME in $FLYE $CANU do BASE = ` basename $GENOME | cut -f 1 -d '.' ` nucmer \\ --prefix = $PROJDIR /quality_control/mummer/Ler_ ${ BASE } \\ --breaklen 1000 \\ --mincluster 1000 \\ $REFERENCE \\ $GENOME mummerplot \\ $PROJDIR /quality_control/mummer/Ler_ ${ BASE } .delta \\ -R $REFERENCE \\ -Q $GENOME \\ --filter \\ -p $PROJDIR /quality_control/mummer/Ler_ ${ BASE } _plot \\ -t png \\ --fat \\ --large \\ --layout done","title":"Run nucmer and mummer"}]}